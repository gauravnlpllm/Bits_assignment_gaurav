{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f26fc56-c8cd-4475-8d1f-8316272ceab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', '.', 'It', 'involves', 'the', 'interactions', 'between', 'computers', 'and', 'humans', 'using', 'the', 'natural', 'language', '.', 'The', 'ultimate', 'objective', 'of', 'NLP', 'is', 'to', 'read', ',', 'decipher', ',', 'understand', ',', 'and', 'make', 'sense', 'of', 'the', 'human', 'language', 'in', 'a', 'valuable', 'way', '.', 'It', 'started', 'in', 'the', '1950s', ',', 'although', 'work', 'can', 'be', 'found', 'from', 'earlier', 'periods', '.', 'In', '1950', ',', 'Alan', 'Turing', 'published', 'an', 'article', 'titled', \"''\", 'Computing', 'Machinery', 'and', 'Intelligence', \"''\", 'which', 'proposed', 'what', 'is', 'now', 'called', 'the', 'Turing', 'test', 'as', 'a', 'criterion', 'of', 'intelligence', ',', 'a', 'task', 'that', 'involves', 'the', 'automated', 'interpretation', 'and', 'generation', 'of', 'natural', 'language', ',', 'but', 'at', 'the', 'time', 'not', 'articulated', 'as', 'a', 'problem', 'separate', 'from', 'artificial', 'intelligence', '.', 'The', 'premise', 'of', 'symbolic', 'NLP', 'is', 'well-summarized', 'by', 'John', 'Searle', \"'s\", 'Chinese', 'room', 'experiment', ':', 'Given', 'a', 'collection', 'of', 'rules', '(', 'e.g.', ',', 'a', 'Chinese', 'phrasebook', ',', 'with', 'questions', 'and', 'matching', 'answers', ')', ',', 'the', 'computer', 'emulates', 'natural', 'language', 'understanding', '(', 'or', 'other', 'NLP', 'tasks', ')', 'by', 'applying', 'those', 'rules', 'to', 'the', 'data', 'it', 'is', 'confronted', 'with', '.', '2023', 'is', 'the', 'year', 'when', 'NLP', 'got', 'its', 'major', 'breakthrough', '.']\n",
      "Filtered tokens (after stop word removal): ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'artificial', 'intelligence', '.', 'involves', 'interactions', 'computers', 'humans', 'using', 'natural', 'language', '.', 'ultimate', 'objective', 'NLP', 'read', ',', 'decipher', ',', 'understand', ',', 'make', 'sense', 'human', 'language', 'valuable', 'way', '.', 'started', '1950s', ',', 'although', 'work', 'found', 'earlier', 'periods', '.', '1950', ',', 'Alan', 'Turing', 'published', 'article', 'titled', \"''\", 'Computing', 'Machinery', 'Intelligence', \"''\", 'proposed', 'called', 'Turing', 'test', 'criterion', 'intelligence', ',', 'task', 'involves', 'automated', 'interpretation', 'generation', 'natural', 'language', ',', 'time', 'articulated', 'problem', 'separate', 'artificial', 'intelligence', '.', 'premise', 'symbolic', 'NLP', 'well-summarized', 'John', 'Searle', \"'s\", 'Chinese', 'room', 'experiment', ':', 'Given', 'collection', 'rules', '(', 'e.g.', ',', 'Chinese', 'phrasebook', ',', 'questions', 'matching', 'answers', ')', ',', 'computer', 'emulates', 'natural', 'language', 'understanding', '(', 'NLP', 'tasks', ')', 'applying', 'rules', 'data', 'confronted', '.', '2023', 'year', 'NLP', 'got', 'major', 'breakthrough', '.']\n",
      "Stemmed tokens: ['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'artifici', 'intellig', '.', 'involv', 'interact', 'comput', 'human', 'use', 'natur', 'languag', '.', 'ultim', 'object', 'nlp', 'read', ',', 'deciph', ',', 'understand', ',', 'make', 'sens', 'human', 'languag', 'valuabl', 'way', '.', 'start', '1950', ',', 'although', 'work', 'found', 'earlier', 'period', '.', '1950', ',', 'alan', 'ture', 'publish', 'articl', 'titl', \"''\", 'comput', 'machineri', 'intellig', \"''\", 'propos', 'call', 'ture', 'test', 'criterion', 'intellig', ',', 'task', 'involv', 'autom', 'interpret', 'gener', 'natur', 'languag', ',', 'time', 'articul', 'problem', 'separ', 'artifici', 'intellig', '.', 'premis', 'symbol', 'nlp', 'well-summar', 'john', 'searl', \"'s\", 'chines', 'room', 'experi', ':', 'given', 'collect', 'rule', '(', 'e.g.', ',', 'chines', 'phrasebook', ',', 'question', 'match', 'answer', ')', ',', 'comput', 'emul', 'natur', 'languag', 'understand', '(', 'nlp', 'task', ')', 'appli', 'rule', 'data', 'confront', '.', '2023', 'year', 'nlp', 'got', 'major', 'breakthrough', '.']\n",
      "Lemmatized tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'artificial', 'intelligence', '.', 'involves', 'interaction', 'computer', 'human', 'using', 'natural', 'language', '.', 'ultimate', 'objective', 'NLP', 'read', ',', 'decipher', ',', 'understand', ',', 'make', 'sense', 'human', 'language', 'valuable', 'way', '.', 'started', '1950s', ',', 'although', 'work', 'found', 'earlier', 'period', '.', '1950', ',', 'Alan', 'Turing', 'published', 'article', 'titled', \"''\", 'Computing', 'Machinery', 'Intelligence', \"''\", 'proposed', 'called', 'Turing', 'test', 'criterion', 'intelligence', ',', 'task', 'involves', 'automated', 'interpretation', 'generation', 'natural', 'language', ',', 'time', 'articulated', 'problem', 'separate', 'artificial', 'intelligence', '.', 'premise', 'symbolic', 'NLP', 'well-summarized', 'John', 'Searle', \"'s\", 'Chinese', 'room', 'experiment', ':', 'Given', 'collection', 'rule', '(', 'e.g.', ',', 'Chinese', 'phrasebook', ',', 'question', 'matching', 'answer', ')', ',', 'computer', 'emulates', 'natural', 'language', 'understanding', '(', 'NLP', 'task', ')', 'applying', 'rule', 'data', 'confronted', '.', '2023', 'year', 'NLP', 'got', 'major', 'breakthrough', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Text\n",
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer \n",
    "science, and artificial intelligence. \n",
    "It involves the interactions between computers and humans using the natural \n",
    "language. The ultimate objective \n",
    "of NLP is to read, decipher, understand, and make sense of the human language in\n",
    "a valuable way. It started \n",
    "in the 1950s, although work can be found from earlier periods. In 1950, Alan \n",
    "Turing published an article titled \n",
    "\"Computing Machinery and Intelligence\" which proposed what is now called the \n",
    "Turing test as a criterion of \n",
    "intelligence, a task that involves the automated interpretation and generation \n",
    "of natural language, but at the \n",
    "time not articulated as a problem separate from artificial intelligence. The \n",
    "premise of symbolic NLP is \n",
    "well-summarized by John Searle's Chinese room experiment: Given a collection of \n",
    "rules (e.g., a Chinese phrasebook, \n",
    "with questions and matching answers), the computer emulates natural language \n",
    "understanding (or other NLP tasks) \n",
    "by applying those rules to the data it is confronted with. 2023 is the year when\n",
    "NLP got its major breakthrough.\n",
    "\"\"\"\n",
    "\n",
    "# Task 1: Tokenization\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Task 2: Stop Word Removal\n",
    "def remove_stop_words(tokens):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Task 3: Stemming\n",
    "def perform_stemming(filtered_tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "# Task 4: Lemmatization\n",
    "def perform_lemmatization(filtered_tokens):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Now use the functions to process the text\n",
    "tokens = tokenize_text(text)\n",
    "filtered_tokens = remove_stop_words(tokens)\n",
    "stemmed_tokens = perform_stemming(filtered_tokens)\n",
    "lemmatized_tokens = perform_lemmatization(filtered_tokens)\n",
    "\n",
    "print(\"Tokenized tokens:\", tokens)\n",
    "print(\"Filtered tokens (after stop word removal):\", filtered_tokens)\n",
    "print(\"Stemmed tokens:\", stemmed_tokens)\n",
    "print(\"Lemmatized tokens:\", lemmatized_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
